[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
MACs: 1,031,744.0
Parameters: 20,490.0
Epoch: [1/25], Step: [100/468], Loss: 1.2076 Acc: 61.79%
Epoch: [1/25], Step: [200/468], Loss: 0.7563 Acc: 76.34%
Epoch: [1/25], Step: [300/468], Loss: 0.5748 Acc: 82.06%
Epoch: [1/25], Step: [400/468], Loss: 0.4717 Acc: 85.36%
Test accuracy: 95.95 % Test loss: 0.1336
Epoch: [2/25], Step: [100/468], Loss: 0.1243 Acc: 96.18%
Epoch: [2/25], Step: [200/468], Loss: 0.1156 Acc: 96.43%
Epoch: [2/25], Step: [300/468], Loss: 0.1138 Acc: 96.56%
Epoch: [2/25], Step: [400/468], Loss: 0.1114 Acc: 96.63%
Test accuracy: 97.44 % Test loss: 0.0786
Epoch: [3/25], Step: [100/468], Loss: 0.0787 Acc: 97.57%
Epoch: [3/25], Step: [200/468], Loss: 0.0818 Acc: 97.52%
Epoch: [3/25], Step: [300/468], Loss: 0.0824 Acc: 97.52%
Epoch: [3/25], Step: [400/468], Loss: 0.0807 Acc: 97.52%
Test accuracy: 97.94 % Test loss: 0.0606
Epoch: [4/25], Step: [100/468], Loss: 0.0697 Acc: 97.89%
Epoch: [4/25], Step: [200/468], Loss: 0.0673 Acc: 98.01%
Epoch: [4/25], Step: [300/468], Loss: 0.0673 Acc: 98.00%
Epoch: [4/25], Step: [400/468], Loss: 0.0672 Acc: 97.96%
Test accuracy: 98.16 % Test loss: 0.0527
Epoch: [5/25], Step: [100/468], Loss: 0.0610 Acc: 98.01%
Epoch: [5/25], Step: [200/468], Loss: 0.0612 Acc: 98.08%
Epoch: [5/25], Step: [300/468], Loss: 0.0599 Acc: 98.15%
Epoch: [5/25], Step: [400/468], Loss: 0.0584 Acc: 98.21%
Test accuracy: 98.53 % Test loss: 0.0471
Epoch: [6/25], Step: [100/468], Loss: 0.0552 Acc: 98.28%
Epoch: [6/25], Step: [200/468], Loss: 0.0534 Acc: 98.39%
Epoch: [6/25], Step: [300/468], Loss: 0.0539 Acc: 98.33%
Epoch: [6/25], Step: [400/468], Loss: 0.0542 Acc: 98.33%
Test accuracy: 98.35 % Test loss: 0.0453
Epoch: [7/25], Step: [100/468], Loss: 0.0487 Acc: 98.62%
Epoch: [7/25], Step: [200/468], Loss: 0.0485 Acc: 98.62%
Epoch: [7/25], Step: [300/468], Loss: 0.0497 Acc: 98.52%
Epoch: [7/25], Step: [400/468], Loss: 0.0483 Acc: 98.57%
Test accuracy: 98.61 % Test loss: 0.0414
Epoch: [8/25], Step: [100/468], Loss: 0.0407 Acc: 98.66%
Epoch: [8/25], Step: [200/468], Loss: 0.0425 Acc: 98.66%
Epoch: [8/25], Step: [300/468], Loss: 0.0444 Acc: 98.65%
Epoch: [8/25], Step: [400/468], Loss: 0.0450 Acc: 98.63%
Test accuracy: 98.55 % Test loss: 0.0436
Epoch: [9/25], Step: [100/468], Loss: 0.0385 Acc: 98.79%
Epoch: [9/25], Step: [200/468], Loss: 0.0410 Acc: 98.72%
Epoch: [9/25], Step: [300/468], Loss: 0.0415 Acc: 98.72%
Epoch: [9/25], Step: [400/468], Loss: 0.0415 Acc: 98.73%
Test accuracy: 98.54 % Test loss: 0.0438
Epoch: [10/25], Step: [100/468], Loss: 0.0397 Acc: 98.71%
Epoch: [10/25], Step: [200/468], Loss: 0.0389 Acc: 98.74%
Epoch: [10/25], Step: [300/468], Loss: 0.0391 Acc: 98.74%
Epoch: [10/25], Step: [400/468], Loss: 0.0399 Acc: 98.71%
Test accuracy: 98.87 % Test loss: 0.0351
Epoch: [11/25], Step: [100/468], Loss: 0.0389 Acc: 98.83%
Epoch: [11/25], Step: [200/468], Loss: 0.0391 Acc: 98.83%
Epoch: [11/25], Step: [300/468], Loss: 0.0392 Acc: 98.83%
Epoch: [11/25], Step: [400/468], Loss: 0.0382 Acc: 98.84%
Test accuracy: 98.67 % Test loss: 0.0422
Epoch: [12/25], Step: [100/468], Loss: 0.0327 Acc: 98.93%
Epoch: [12/25], Step: [200/468], Loss: 0.0356 Acc: 98.84%
Epoch: [12/25], Step: [300/468], Loss: 0.0359 Acc: 98.84%
Epoch: [12/25], Step: [400/468], Loss: 0.0348 Acc: 98.89%
Test accuracy: 98.64 % Test loss: 0.0443
Epoch: [13/25], Step: [100/468], Loss: 0.0330 Acc: 99.00%
Epoch: [13/25], Step: [200/468], Loss: 0.0307 Acc: 99.10%
Epoch: [13/25], Step: [300/468], Loss: 0.0303 Acc: 99.08%
Epoch: [13/25], Step: [400/468], Loss: 0.0322 Acc: 98.99%
Test accuracy: 98.78 % Test loss: 0.0356
Epoch: [14/25], Step: [100/468], Loss: 0.0354 Acc: 98.91%
Epoch: [14/25], Step: [200/468], Loss: 0.0321 Acc: 99.01%
Epoch: [14/25], Step: [300/468], Loss: 0.0322 Acc: 99.03%
Epoch: [14/25], Step: [400/468], Loss: 0.0317 Acc: 99.03%
Test accuracy: 98.76 % Test loss: 0.0357
Epoch: [15/25], Step: [100/468], Loss: 0.0307 Acc: 99.12%
Epoch: [15/25], Step: [200/468], Loss: 0.0311 Acc: 99.09%
Epoch: [15/25], Step: [300/468], Loss: 0.0305 Acc: 99.10%
Epoch: [15/25], Step: [400/468], Loss: 0.0309 Acc: 99.04%
Test accuracy: 98.87 % Test loss: 0.0336
Epoch: [16/25], Step: [100/468], Loss: 0.0297 Acc: 99.15%
Epoch: [16/25], Step: [200/468], Loss: 0.0295 Acc: 99.09%
Epoch: [16/25], Step: [300/468], Loss: 0.0272 Acc: 99.16%
Epoch: [16/25], Step: [400/468], Loss: 0.0285 Acc: 99.12%
Test accuracy: 98.73 % Test loss: 0.0377
Epoch: [17/25], Step: [100/468], Loss: 0.0278 Acc: 99.21%
Epoch: [17/25], Step: [200/468], Loss: 0.0263 Acc: 99.20%
Epoch: [17/25], Step: [300/468], Loss: 0.0276 Acc: 99.16%
Epoch: [17/25], Step: [400/468], Loss: 0.0284 Acc: 99.13%
Test accuracy: 98.95 % Test loss: 0.0326
Epoch: [18/25], Step: [100/468], Loss: 0.0207 Acc: 99.27%
Epoch: [18/25], Step: [200/468], Loss: 0.0255 Acc: 99.14%
Epoch: [18/25], Step: [300/468], Loss: 0.0264 Acc: 99.13%
Epoch: [18/25], Step: [400/468], Loss: 0.0271 Acc: 99.15%
Test accuracy: 98.69 % Test loss: 0.0372
Epoch: [19/25], Step: [100/468], Loss: 0.0245 Acc: 99.26%
Epoch: [19/25], Step: [200/468], Loss: 0.0235 Acc: 99.27%
Epoch: [19/25], Step: [300/468], Loss: 0.0237 Acc: 99.26%
Epoch: [19/25], Step: [400/468], Loss: 0.0255 Acc: 99.21%
Test accuracy: 98.90 % Test loss: 0.0336
Epoch: [20/25], Step: [100/468], Loss: 0.0233 Acc: 99.26%
Epoch: [20/25], Step: [200/468], Loss: 0.0231 Acc: 99.26%
Epoch: [20/25], Step: [300/468], Loss: 0.0249 Acc: 99.23%
Epoch: [20/25], Step: [400/468], Loss: 0.0244 Acc: 99.22%
Test accuracy: 98.64 % Test loss: 0.0382
Epoch: [21/25], Step: [100/468], Loss: 0.0243 Acc: 99.23%
Epoch: [21/25], Step: [200/468], Loss: 0.0238 Acc: 99.27%
Epoch: [21/25], Step: [300/468], Loss: 0.0239 Acc: 99.27%
Epoch: [21/25], Step: [400/468], Loss: 0.0231 Acc: 99.28%
Test accuracy: 98.75 % Test loss: 0.0384
Epoch: [22/25], Step: [100/468], Loss: 0.0192 Acc: 99.47%
Epoch: [22/25], Step: [200/468], Loss: 0.0196 Acc: 99.44%
Epoch: [22/25], Step: [300/468], Loss: 0.0201 Acc: 99.40%
Epoch: [22/25], Step: [400/468], Loss: 0.0210 Acc: 99.36%
Test accuracy: 98.80 % Test loss: 0.0367
Epoch: [23/25], Step: [100/468], Loss: 0.0202 Acc: 99.29%
Epoch: [23/25], Step: [200/468], Loss: 0.0203 Acc: 99.30%
Epoch: [23/25], Step: [300/468], Loss: 0.0213 Acc: 99.30%
Epoch: [23/25], Step: [400/468], Loss: 0.0211 Acc: 99.32%
Test accuracy: 98.76 % Test loss: 0.0420
Epoch: [24/25], Step: [100/468], Loss: 0.0190 Acc: 99.51%
Epoch: [24/25], Step: [200/468], Loss: 0.0205 Acc: 99.37%
Epoch: [24/25], Step: [300/468], Loss: 0.0200 Acc: 99.37%
Epoch: [24/25], Step: [400/468], Loss: 0.0203 Acc: 99.34%
Test accuracy: 98.82 % Test loss: 0.0373
Epoch: [25/25], Step: [100/468], Loss: 0.0171 Acc: 99.52%
Epoch: [25/25], Step: [200/468], Loss: 0.0188 Acc: 99.50%
Epoch: [25/25], Step: [300/468], Loss: 0.0188 Acc: 99.47%
Epoch: [25/25], Step: [400/468], Loss: 0.0193 Acc: 99.42%
Test accuracy: 98.93 % Test loss: 0.0328
Model size: 0.08 MB
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 28, 28]             160
         MaxPool2d-2           [-1, 16, 14, 14]               0
            Conv2d-3           [-1, 32, 14, 14]           4,640
         MaxPool2d-4             [-1, 32, 7, 7]               0
            Linear-5                   [-1, 10]          15,690
================================================================
Total params: 20,490
Trainable params: 20,490
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.18
Params size (MB): 0.08
Estimated Total Size (MB): 0.26
----------------------------------------------------------------
