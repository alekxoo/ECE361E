[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
MACs: 290,080.0
Parameters: 9,098.0
Epoch: [1/25], Step: [100/468], Loss: 1.4018 Acc: 54.86%
Epoch: [1/25], Step: [200/468], Loss: 0.8820 Acc: 71.88%
Epoch: [1/25], Step: [300/468], Loss: 0.6718 Acc: 78.69%
Epoch: [1/25], Step: [400/468], Loss: 0.5547 Acc: 82.45%
Test accuracy: 94.86 % Test loss: 0.1715
Epoch: [2/25], Step: [100/468], Loss: 0.1484 Acc: 95.60%
Epoch: [2/25], Step: [200/468], Loss: 0.1419 Acc: 95.70%
Epoch: [2/25], Step: [300/468], Loss: 0.1393 Acc: 95.77%
Epoch: [2/25], Step: [400/468], Loss: 0.1364 Acc: 95.87%
Test accuracy: 96.95 % Test loss: 0.0953
Epoch: [3/25], Step: [100/468], Loss: 0.0921 Acc: 97.25%
Epoch: [3/25], Step: [200/468], Loss: 0.0961 Acc: 97.16%
Epoch: [3/25], Step: [300/468], Loss: 0.0962 Acc: 97.12%
Epoch: [3/25], Step: [400/468], Loss: 0.0935 Acc: 97.17%
Test accuracy: 97.84 % Test loss: 0.0697
Epoch: [4/25], Step: [100/468], Loss: 0.0795 Acc: 97.67%
Epoch: [4/25], Step: [200/468], Loss: 0.0769 Acc: 97.83%
Epoch: [4/25], Step: [300/468], Loss: 0.0763 Acc: 97.84%
Epoch: [4/25], Step: [400/468], Loss: 0.0756 Acc: 97.81%
Test accuracy: 97.98 % Test loss: 0.0635
Epoch: [5/25], Step: [100/468], Loss: 0.0678 Acc: 97.79%
Epoch: [5/25], Step: [200/468], Loss: 0.0684 Acc: 97.86%
Epoch: [5/25], Step: [300/468], Loss: 0.0673 Acc: 97.94%
Epoch: [5/25], Step: [400/468], Loss: 0.0654 Acc: 98.00%
Test accuracy: 98.50 % Test loss: 0.0507
Epoch: [6/25], Step: [100/468], Loss: 0.0626 Acc: 98.09%
Epoch: [6/25], Step: [200/468], Loss: 0.0601 Acc: 98.18%
Epoch: [6/25], Step: [300/468], Loss: 0.0607 Acc: 98.14%
Epoch: [6/25], Step: [400/468], Loss: 0.0599 Acc: 98.21%
Test accuracy: 98.03 % Test loss: 0.0569
Epoch: [7/25], Step: [100/468], Loss: 0.0543 Acc: 98.34%
Epoch: [7/25], Step: [200/468], Loss: 0.0546 Acc: 98.39%
Epoch: [7/25], Step: [300/468], Loss: 0.0555 Acc: 98.34%
Epoch: [7/25], Step: [400/468], Loss: 0.0537 Acc: 98.40%
Test accuracy: 98.49 % Test loss: 0.0450
Epoch: [8/25], Step: [100/468], Loss: 0.0438 Acc: 98.62%
Epoch: [8/25], Step: [200/468], Loss: 0.0472 Acc: 98.55%
Epoch: [8/25], Step: [300/468], Loss: 0.0493 Acc: 98.49%
Epoch: [8/25], Step: [400/468], Loss: 0.0494 Acc: 98.49%
Test accuracy: 98.51 % Test loss: 0.0431
Epoch: [9/25], Step: [100/468], Loss: 0.0419 Acc: 98.66%
Epoch: [9/25], Step: [200/468], Loss: 0.0464 Acc: 98.61%
Epoch: [9/25], Step: [300/468], Loss: 0.0471 Acc: 98.60%
Epoch: [9/25], Step: [400/468], Loss: 0.0467 Acc: 98.61%
Test accuracy: 98.49 % Test loss: 0.0468
Epoch: [10/25], Step: [100/468], Loss: 0.0437 Acc: 98.57%
Epoch: [10/25], Step: [200/468], Loss: 0.0441 Acc: 98.59%
Epoch: [10/25], Step: [300/468], Loss: 0.0451 Acc: 98.54%
Epoch: [10/25], Step: [400/468], Loss: 0.0448 Acc: 98.56%
Test accuracy: 98.72 % Test loss: 0.0373
Epoch: [11/25], Step: [100/468], Loss: 0.0432 Acc: 98.74%
Epoch: [11/25], Step: [200/468], Loss: 0.0434 Acc: 98.74%
Epoch: [11/25], Step: [300/468], Loss: 0.0438 Acc: 98.69%
Epoch: [11/25], Step: [400/468], Loss: 0.0426 Acc: 98.71%
Test accuracy: 98.44 % Test loss: 0.0466
Epoch: [12/25], Step: [100/468], Loss: 0.0374 Acc: 98.74%
Epoch: [12/25], Step: [200/468], Loss: 0.0423 Acc: 98.62%
Epoch: [12/25], Step: [300/468], Loss: 0.0418 Acc: 98.66%
Epoch: [12/25], Step: [400/468], Loss: 0.0403 Acc: 98.73%
Test accuracy: 98.42 % Test loss: 0.0461
Epoch: [13/25], Step: [100/468], Loss: 0.0391 Acc: 98.74%
Epoch: [13/25], Step: [200/468], Loss: 0.0364 Acc: 98.87%
Epoch: [13/25], Step: [300/468], Loss: 0.0367 Acc: 98.87%
Epoch: [13/25], Step: [400/468], Loss: 0.0380 Acc: 98.83%
Test accuracy: 98.73 % Test loss: 0.0398
Epoch: [14/25], Step: [100/468], Loss: 0.0395 Acc: 98.80%
Epoch: [14/25], Step: [200/468], Loss: 0.0371 Acc: 98.84%
Epoch: [14/25], Step: [300/468], Loss: 0.0370 Acc: 98.88%
Epoch: [14/25], Step: [400/468], Loss: 0.0364 Acc: 98.90%
Test accuracy: 98.67 % Test loss: 0.0403
Epoch: [15/25], Step: [100/468], Loss: 0.0374 Acc: 98.87%
Epoch: [15/25], Step: [200/468], Loss: 0.0371 Acc: 98.89%
Epoch: [15/25], Step: [300/468], Loss: 0.0361 Acc: 98.90%
Epoch: [15/25], Step: [400/468], Loss: 0.0359 Acc: 98.91%
Test accuracy: 98.74 % Test loss: 0.0370
Epoch: [16/25], Step: [100/468], Loss: 0.0352 Acc: 98.95%
Epoch: [16/25], Step: [200/468], Loss: 0.0369 Acc: 98.80%
Epoch: [16/25], Step: [300/468], Loss: 0.0333 Acc: 98.95%
Epoch: [16/25], Step: [400/468], Loss: 0.0343 Acc: 98.93%
Test accuracy: 98.58 % Test loss: 0.0426
Epoch: [17/25], Step: [100/468], Loss: 0.0322 Acc: 99.04%
Epoch: [17/25], Step: [200/468], Loss: 0.0310 Acc: 99.07%
Epoch: [17/25], Step: [300/468], Loss: 0.0327 Acc: 99.01%
Epoch: [17/25], Step: [400/468], Loss: 0.0329 Acc: 98.99%
Test accuracy: 98.65 % Test loss: 0.0397
Epoch: [18/25], Step: [100/468], Loss: 0.0258 Acc: 99.18%
Epoch: [18/25], Step: [200/468], Loss: 0.0291 Acc: 99.06%
Epoch: [18/25], Step: [300/468], Loss: 0.0315 Acc: 98.98%
Epoch: [18/25], Step: [400/468], Loss: 0.0318 Acc: 99.01%
Test accuracy: 98.70 % Test loss: 0.0373
Epoch: [19/25], Step: [100/468], Loss: 0.0302 Acc: 99.04%
Epoch: [19/25], Step: [200/468], Loss: 0.0286 Acc: 99.11%
Epoch: [19/25], Step: [300/468], Loss: 0.0285 Acc: 99.10%
Epoch: [19/25], Step: [400/468], Loss: 0.0300 Acc: 99.05%
Test accuracy: 98.83 % Test loss: 0.0358
Epoch: [20/25], Step: [100/468], Loss: 0.0286 Acc: 99.17%
Epoch: [20/25], Step: [200/468], Loss: 0.0276 Acc: 99.16%
Epoch: [20/25], Step: [300/468], Loss: 0.0291 Acc: 99.11%
Epoch: [20/25], Step: [400/468], Loss: 0.0289 Acc: 99.11%
Test accuracy: 98.61 % Test loss: 0.0396
Epoch: [21/25], Step: [100/468], Loss: 0.0279 Acc: 99.16%
Epoch: [21/25], Step: [200/468], Loss: 0.0282 Acc: 99.17%
Epoch: [21/25], Step: [300/468], Loss: 0.0288 Acc: 99.15%
Epoch: [21/25], Step: [400/468], Loss: 0.0278 Acc: 99.16%
Test accuracy: 98.56 % Test loss: 0.0437
Epoch: [22/25], Step: [100/468], Loss: 0.0276 Acc: 99.12%
Epoch: [22/25], Step: [200/468], Loss: 0.0273 Acc: 99.12%
Epoch: [22/25], Step: [300/468], Loss: 0.0262 Acc: 99.16%
Epoch: [22/25], Step: [400/468], Loss: 0.0272 Acc: 99.14%
Test accuracy: 98.78 % Test loss: 0.0373
Epoch: [23/25], Step: [100/468], Loss: 0.0259 Acc: 99.11%
Epoch: [23/25], Step: [200/468], Loss: 0.0255 Acc: 99.18%
Epoch: [23/25], Step: [300/468], Loss: 0.0272 Acc: 99.14%
Epoch: [23/25], Step: [400/468], Loss: 0.0265 Acc: 99.17%
Test accuracy: 98.62 % Test loss: 0.0425
Epoch: [24/25], Step: [100/468], Loss: 0.0223 Acc: 99.31%
Epoch: [24/25], Step: [200/468], Loss: 0.0257 Acc: 99.18%
Epoch: [24/25], Step: [300/468], Loss: 0.0253 Acc: 99.21%
Epoch: [24/25], Step: [400/468], Loss: 0.0255 Acc: 99.19%
Test accuracy: 98.68 % Test loss: 0.0407
Epoch: [25/25], Step: [100/468], Loss: 0.0236 Acc: 99.37%
Epoch: [25/25], Step: [200/468], Loss: 0.0242 Acc: 99.36%
Epoch: [25/25], Step: [300/468], Loss: 0.0251 Acc: 99.29%
Epoch: [25/25], Step: [400/468], Loss: 0.0251 Acc: 99.27%
Test accuracy: 98.78 % Test loss: 0.0361
Model size: 0.04 MB
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [-1, 8, 28, 28]              80
         MaxPool2d-2            [-1, 8, 14, 14]               0
            Conv2d-3           [-1, 16, 14, 14]           1,168
         MaxPool2d-4             [-1, 16, 7, 7]               0
            Linear-5                   [-1, 10]           7,850
================================================================
Total params: 9,098
Trainable params: 9,098
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.09
Params size (MB): 0.03
Estimated Total Size (MB): 0.13
----------------------------------------------------------------
